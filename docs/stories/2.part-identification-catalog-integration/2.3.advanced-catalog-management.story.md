# Story 2.3: Advanced Catalog Management

## Status

Done

## Story

**As a** user,
**I want** intelligent catalog management with API passthrough,
**so that** I have access to comprehensive part data while respecting API limits.

## Acceptance Criteria

1. **2.3.1:** System maintains global catalog database of Lego parts and their Bricklink pricing data
2. **2.3.2:** System fetches missing or stale parts and pricing (30 days+) from Bricklink API automatically
3. **2.3.3:** System implements intelligent caching
4. **2.3.4:** System respects API rate limits and handles throttling
5. **2.3.5:** System validates data freshness and updates as needed
6. **2.3.6:** System handles API failures with appropriate fallback mechanisms
7. **2.3.7:** Catalog data includes images, part numbers, colors, market pricing, list of colors part comes in, obsolete flag, dimensions, weight, printed indicator, etc.

## Tasks / Subtasks

- [x] Task 1: Global catalog data model and freshness fields (AC: 2.3.1, 2.3.5, 2.3.7)

  - [x] Ensure `LegoPartCatalog` persists global (non-tenant) part records with pricing and freshness timestamps, aligning with overlay pattern for tenant-specific metadata. Add/confirm fields supporting data freshness windows and completeness (e.g., `marketPrice`, `marketPriceLastSyncedAt`, `lastFetchedFromBricklink`, `dataFreshness`, `availableColorIds`, `dimensions`, `weight`, `isPrinted`, `isObsolete`). [Source: docs/architecture/data-models.md#legopartcatalog; docs/architecture/data-models.md#global-catalog--tenant-overlays-update-2025-09-26]
  - [x] Add/confirm indexes to support freshness scans and efficient lookup by `partNumber`, and any freshness-based queries used by refresh pipelines. [Source: docs/architecture/backend-architecture.md#catalog-data-refresh-lifecycle]

- [x] Task 2: Automatic refresh pipelines for stale/missing data (AC: 2.3.2, 2.3.5)

  - [x] Implement/extend Convex pipeline(s) to refresh parts considered stale (>30 days) and expired (>60 days) with background jobs; kick off on-demand refresh when cache miss occurs. [Source: docs/prd/epic-2-part-identification-catalog-integration.md#catalog-data-strategy]
  - [x] Orchestrate Bricklink calls across `/items/part`, `/items/part/{no}`, `/items/part/{no}/price`, `/colors`, `/categories` and aggregate results into catalog records; record per-call timing and update freshness timestamps. [Source: docs/architecture/components.md#catalogservice; docs/external-documentation/apis/bricklink.md]
  - [x] Wire scheduled refresh cadence via `convex/crons.ts` to maintain freshness windows without breaching quotas. [Source: docs/architecture/backend-architecture.md#service-architecture-serverless]

- [x] Task 3: Intelligent caching layers (AC: 2.3.3)

  - [x] Prefer local datastore responses first; emit cache hit/miss metrics and only call Bricklink on cache miss or staleness threshold breach. [Source: docs/architecture/security-and-performance.md#performance-optimization]
  - [x] Implement per-request memoization/short-lived in-process cache where safe to reduce repeated upstream calls within a request burst. [Source: docs/architecture/security-and-performance.md#performance-optimization]

- [x] Task 4: API rate limiting and throttling (AC: 2.3.4)

  - [x] Adopt Convex Rate Limiter component for backend→third‑party calls; centralize Bricklink limits with token bucket/fixed window configs (e.g., day/minute quotas, optional capacity for bounded bursts). [Source: docs/architecture/security-and-performance.md#security-requirements]
  - [x] Enforce limits server‑side before issuing Bricklink requests (transactional check in Convex mutation/action); replace in‑memory limiter usage in outbound client with Convex limiter to ensure correctness across workers. [Source: docs/architecture/security-and-performance.md#security-requirements]
  - [x] Use reservations + scheduler: when limited, call `reserve: true` and queue with `ctx.scheduler.runAfter(retryAfter + jitter, …)` to prevent thundering herds and starvation of large requests. [Source: docs/architecture/security-and-performance.md#security-requirements]
  - [x] Add sharding for high‑contention global limits (power‑of-two choice) to reduce OCC retries under load while maintaining hard caps. [Source: docs/architecture/security-and-performance.md#security-requirements]
  - [x] Surface quota/limit telemetry for observability dashboards. [Source: docs/architecture/monitoring-and-observability.md#key-metrics]

- [x] Task 5: Freshness validation API and utilities (AC: 2.3.5)

  - [x] Implement/extend `CatalogService.validateDataFreshness` to return freshness states for parts/pricing and trigger background refresh for borderline cases. [Source: docs/architecture/components.md#catalogservice]
  - [x] Add helpers to compute windows (fresh <30 days, background 30–60 days, expired >60 days) and expose next refresh suggestion. [Source: docs/prd/epic-2-part-identification-catalog-integration.md#catalog-data-strategy]

- [x] Task 6: Failure handling and fallbacks (AC: 2.3.6)

  - [x] Map upstream errors to structured error objects; on fetch failures, serve last-known-good cached data and annotate response with freshness/partial indicators. [Source: docs/architecture/error-handling-strategy.md]
  - [x] Add retry-with-backoff and circuit-breaker semantics for repeated upstream failures within time windows. [Source: docs/architecture/security-and-performance.md#performance-optimization]

- [x] Task 7: Catalog completeness fields population (AC: 2.3.7)

  - [x] Ensure aggregation captures and stores: images, part numbers, list of available colors, obsolete status, dimensions, weight, printed indicator, and market pricing. Map each attribute to its Bricklink source endpoint and normalize. [Source: docs/external-documentation/apis/bricklink.md]

- [x] Task 8: Metrics and monitoring (AC: 2.3.2, 2.3.3, 2.3.4, 2.3.6)

  - [x] Record metrics for cache hit rate, refresh durations, quota consumption, backoff activations, and fallback usage. [Source: docs/architecture/monitoring-and-observability.md#key-metrics]
  - [x] Add logs/traces to diagnose slow queries and upstream latency.

- [x] Task 9: Comprehensive validation and testing (AC: 2.3.1–2.3.7)

  - [x] Backend unit/integration tests for freshness windows, rate limiting/backoff, cache behavior, failure fallbacks, and data completeness mapping. [Source: docs/architecture/testing-strategy.md#backend-tests]
  - [x] E2E smoke where applicable (optional) to verify stale → refresh → served path under mocked upstream conditions. [Source: docs/architecture/testing-strategy.md#e2e-tests]

## Dev Notes

### Previous Story Insights

- Catalog search/browse (2.2) established schema extensions, filter metadata tables, SLA instrumentation, and Bricklink fallback patterns. This story must extend those foundations without changing public contracts. [Source: docs/stories/2.2.catalog-search-and-browse.story.md#dev-notes]

### Global Catalog and Overlay Model

- Global catalog/reference datasets are shared across tenants; business-specific attributes live in an overlay keyed by `(businessAccountId, partNumber)`. Catalog refresh jobs operate on the global tables only. [Source: docs/architecture/data-models.md#global-catalog--tenant-overlays-update-2025-09-26]

### Data Freshness Windows and Strategy

- Treat records <30 days as fresh, 30–60 days trigger background refresh, >60 days are expired and require on-demand refresh for reads. Persist timestamps to drive scheduling and on-read decisions. [Source: docs/prd/epic-2-part-identification-catalog-integration.md#catalog-data-strategy]

### API Specifications and Quotas

- Use Bricklink item and price guide endpoints with OAuth 1.0a credentials; enforce 5,000 calls/day budgeting, with backoff on throttling responses. [Source: docs/architecture/api-specification.md#bricklink-oauth-10a-credentials; docs/external-documentation/apis/bricklink.md]

### Rate Limiting and Backoff

- Focus on backend→third‑party API calls (Bricklink): use Convex’s rate limiter patterns (token bucket for overall throughput with optional capacity; fixed window for strict vendor caps) with centralized definitions and transactional enforcement before outbound requests. Prefer server‑side checks over any in‑memory client limiter to avoid cross‑worker inconsistencies. [Source: docs/architecture/security-and-performance.md#security-requirements]
- When limited, return/propagate `retryAfter` and apply jitter; for guaranteed fairness, use `reserve: true` with `ctx.scheduler.runAfter` so large requests are scheduled instead of repeatedly retried. Apply sharding for high‑contention global limits to scale without violating quotas. [Source: docs/architecture/security-and-performance.md#security-requirements]

### Caching Behavior

- Cache-first reads: serve from catalog tables when fresh; otherwise enqueue refresh and optionally return last-known-good with freshness annotations, maintaining ≤2s response targets. [Source: docs/architecture/security-and-performance.md#performance-optimization]

### Monitoring and Observability

- Record metrics for cache hit/miss, refresh latencies, and quota usage; surface counters to dashboards. [Source: docs/architecture/monitoring-and-observability.md#key-metrics]

### File Locations

- Backend logic: `convex/functions/catalog.ts` (refresh orchestration, cache-first reads), helpers under `convex/lib/`, scheduled jobs in `convex/crons.ts`. [Source: docs/architecture/backend-architecture.md#service-architecture-serverless]
- Tests: `__tests__/backend/` and `e2e/` as per testing strategy. [Source: docs/architecture/testing-strategy.md]

### Testing

- Backend (Vitest):

  - Freshness window unit tests for <30 / 30–60 / >60-day behavior (trigger background vs immediate refresh). (AC: 2.3.2, 2.3.5)
  - Rate limiting/backoff tests validating retry ceilings and budget sharing. (AC: 2.3.4)
  - Cache hit/miss behavior and fallback serving with structured errors under simulated upstream failures. (AC: 2.3.3, 2.3.6)
  - Data completeness mapping tests for images, colors, obsolete, dimensions, weight, printed, and pricing. (AC: 2.3.7)

- Integration/E2E (selective):
  - Mocked upstream latency/throttling to verify cache-first response ≤2s while refresh occurs. (AC: 2.3.3, 2.3.6)

## Project Structure Notes

- All updates remain within existing Convex catalog service and cron structure; no changes to frontend routes or component architecture are required for this story. [Source: docs/architecture/source-tree.md; docs/architecture/frontend-architecture.md#routing-architecture]

## Change Log

| Date       | Version | Description                | Author |
| ---------- | ------- | -------------------------- | ------ |
| 2025-10-03 | v1.0    | Initial draft of Story 2.3 | Bob    |
